## 大数据存储与管理  
由于大数据的数据非结构化特征明显，依靠分布式文件系统（DFS）     
分布式文件系统针对大规模数据存储管理而设计，可有效解决备份、安全、可扩展等难题：将固定于某个节点的文件系统，扩展到多个节点，众多的节点组成一个文件系统网络。

### HDFS简介
HDFS的主要设计目标是：    
- 通过自动维护多副本和在故障发生时自动重新部署处理逻辑，实现可靠性 
- 通过 MapReduce 流进行数据访问 
处理逻辑接近数据，而不是数据接近处理逻辑 
- 跨异构普通硬件和操作系统的可移植性 
系统规模可伸缩性好 
- 通过跨多个普通个人计算机集群分布数据和处理，以节约成本 
- 通过分布数据和逻辑到数据所在的多个节点上进行并行处理来提高效率
- HDFS采用 Java 语言开发，提供一个原生 Java 应用程序编程接口（API）和一个针对这个Java API的原生C语言封装器。另外，可以使用Web浏览器来浏览 HDFS 文件      

|应用程序|说明|
|-|-|
|FileSystem(FS)shell|命令行接口，类似于常见的 Linux和UNIX shells（bash、csh，等），支持与 HDFS 数据进行交互|
|DFSAdmin|可用于管理一个HDFS的命令集|
|fsck|Hadoop 命令/应用程序的一个子命令，可使用 fsck 命令来检查文件的不一致（比如缺失块），但不能使用 fsck 命令更正这些不一致|
|Name node 和 
Data node|这些节点拥有内置 web 服务器，允许管理员检查集群的当前状态|

### HDFS体系结构
**HDFS集群主要由管理文件系统元数据的名节点和存储实际数据的数据节点构成**
- 名节点负责文件和目录的创建、删除、重命名等，同时管理数据节点和文件块的映射关系
- 数据节点负责数据的存储与读取
![](HDFSsystem.png)
### HDFS存储原理
- 数据存放
    - 为提高数据可靠性与系统可用性，以及充分利用网络带宽，HDFS 采用以机架为基础的数据存放策略,HDFS数据文件被分成大小固定的块 (默认64MB) 
    - 默认的冗余数据复制因子是 3，每一个文件块会被同时保存到 3 个地方，其中两份副本存放在同一个机架的不同机器，第三个副本放在不同机架的机器，以保证发生故障时（例如机架发生异常）的数据恢复，也可提高数据读写性能
- 存储原理
    - 命名空间管理
    - 数据复制
    - 心跳检测
- HDFS数据读写
![](HDFSread.png)
![](HDFSwrite.png)
---
## 分布式数据库HBase(基于HDFS)
>HBase是用来存储非结构化和半结构化的数据的分布式数据库
### HBase数据模型
行键：表中每条记录的“主键”，方便快速查找    
列族：列族拥有一个名称，包含一个或者多个相关列    
列：列中每条记录可动态添加    
时间戳：进行版本的区分，可由用户自定义    
单元格：值，字节码类型    
- HBase以表的形式来存储数据    
- 每行有一个可排序的主键和任意多的列
- 面向列：同一张表中不同的行可以有截然不同列，面向列（族）的存储和权限控制，列（族）独立检索    
- 数据多版本：每个单元中数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳    
- 稀疏性：空列不占用存储空间，可具有高压缩比

### HBase的功能模块
HBase的功能模块包括主服务器、分区服务器、库函数
![](Hbase1.png)
![](Hbase2.png)
![](Hbase3.png) 
### Zookeeper
![](Zookeeper.png)
![](Zookeeper2.png)
### Hbase的读写
![](Hbase_read.png)
![](Hbase_write.png)



